{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프레임이 아닌 비디오를 모델의 입력으로...\n",
    "model = YOLO('../model/yolov8m-face.pt')\n",
    "videoPath = 'testvideoShorts.mp4'\n",
    "\n",
    "results = model(videoPath, stream=True ,verbose=False,show_labels=False ,device='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for result in results:\n",
    "    ori = result.orig_img\n",
    "    for box in result.boxes:\n",
    "        left_x = int(box.xyxy.tolist()[0][0])\n",
    "        left_y = int(box.xyxy.tolist()[0][1])\n",
    "        right_x = int(box.xyxy.tolist()[0][2])\n",
    "        right_y = int(box.xyxy.tolist()[0][3])\n",
    "        \n",
    "        center_x = (left_x + right_x) // 2\n",
    "        center_y = (left_y + right_y) // 2\n",
    "        axis_major = (right_x - left_x) // 2\n",
    "        axis_minor = (right_y - left_y) // 2\n",
    "        face = ori[left_y:right_y, left_x:right_x]\n",
    "        \n",
    "        ori[left_y:right_y, left_x:right_x] = cv2.blur(face, (40, 40))\n",
    "        \n",
    "        maskShape = (ori.shape[0], ori.shape[1], 1)\n",
    "        mask = np.full(maskShape, 0, dtype=np.uint8)\n",
    "        cv2.ellipse(mask, (center_x, center_y), (axis_major, axis_minor), 0, 0, 360, (255, 255, 255), -1)\n",
    "        mask_inv = cv2.bitwise_not(mask)\n",
    "        img1_bg = cv2.bitwise_and(result.orig_img,result.orig_img,mask = mask_inv)\n",
    "        img2_fg = cv2.bitwise_and(ori,ori,mask = mask)\n",
    "        dst = cv2.add(img1_bg,img2_fg)\n",
    "        ori = dst\n",
    "\n",
    "    ori = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(ori)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for result in results:\n",
    "    ori = result.orig_img\n",
    "    for box in result.boxes:\n",
    "        left_x = int(box.xyxy.tolist()[0][0])\n",
    "        left_y = int(box.xyxy.tolist()[0][1])\n",
    "        right_x = int(box.xyxy.tolist()[0][2])\n",
    "        right_y = int(box.xyxy.tolist()[0][3])\n",
    "        \n",
    "        center_x = (left_x + right_x) // 2\n",
    "        center_y = (left_y + right_y) // 2\n",
    "        axis_major = (right_x - left_x) // 2\n",
    "        axis_minor = (right_y - left_y) // 2\n",
    "        face = ori[left_y:right_y, left_x:right_x]\n",
    "        \n",
    "        mask = np.zeros_like(ori)\n",
    "        cv2.ellipse(mask, (center_x, center_y), (axis_major, axis_minor), 0, 0, 360, (255, 255, 255), -1)\n",
    "        inverse_mask = cv2.bitwise_not(mask)\n",
    "        face_with_ellipse = cv2.bitwise_and(ori, mask)\n",
    "        result = cv2.add(ori, mask)\n",
    "        \n",
    "        # ori[left_y:right_y, left_x:right_x] = cv2.blur(result, (40, 40))\n",
    "        # ori = result\n",
    "    ori = cv2.cvtColor(face_with_ellipse, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(ori)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for result in results:\n",
    "    ori = result.orig_img\n",
    "    for box in result.boxes:\n",
    "        left_x = int(box.xyxy.tolist()[0][0])\n",
    "        left_y = int(box.xyxy.tolist()[0][1])\n",
    "        right_x = int(box.xyxy.tolist()[0][2])\n",
    "        right_y = int(box.xyxy.tolist()[0][3])\n",
    "        \n",
    "        # 타원형 중심과 축 길이 계산\n",
    "        center_x = (left_x + right_x) // 2\n",
    "        center_y = (left_y + right_y) // 2\n",
    "        axis_major = (right_x - left_x) // 2\n",
    "        axis_minor = (right_y - left_y) // 2\n",
    "        \n",
    "        # 타원형 마스크 생성\n",
    "        mask = np.zeros_like(ori)\n",
    "        cv2.ellipse(mask, (center_x, center_y), (axis_major, axis_minor), 0, 0, 360, (255, 255, 255), -1)\n",
    "        \n",
    "        # 원본 이미지 * 타원형 영역\n",
    "        face_with_ellipse = cv2.bitwise_and(ori, mask)\n",
    "        blurred_face = cv2.blur(face_with_ellipse, (40, 40))\n",
    "        \n",
    "        # !(타원형 마스크)\n",
    "        inverse_mask = cv2.bitwise_not(mask)\n",
    "        \n",
    "        # 원본 이미지에서 타원형 영역을 제외한 나머지 부분 추출\n",
    "        background = cv2.bitwise_and(ori, inverse_mask)\n",
    "        result_image = cv2.add(blurred_face, background)\n",
    "\n",
    "        \n",
    "        # ori[left_y:right_y, left_x:right_x] = cv2.blur(result, (40, 40))\n",
    "        ori = result_image\n",
    "    ori = cv2.cvtColor(ori, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(ori)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.BORDER_CONSTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps is useable\n"
     ]
    }
   ],
   "source": [
    "# if (torch.backends.mps.is_available()):\n",
    "#     mps_device = torch.device(\"mps\")\n",
    "#     print(\"mps is useable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 1674/1674.0 [01:44<00:00, 15.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# # 프레임이 아닌 비디오를 모델의 입력으로...\n",
    "# model = YOLO('../model/yolov8m-face.pt')\n",
    "# model.to(mps_device)\n",
    "\n",
    "# videoPath = 'testvideoShorts.mp4'\n",
    "\n",
    "# results = model(videoPath, stream=True ,verbose=False,show_labels=False ,device='mps')\n",
    "\n",
    "\n",
    "# cap = cv2.VideoCapture(videoPath)\n",
    "# fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
    "# w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "# saveVideo = cv2.VideoWriter('outputShortmps.mp4', fourcc, fps, (w, h))\n",
    "# frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "# cap.release()\n",
    "\n",
    "# for result in tqdm(results,  total=frame_count):\n",
    "#     ori = result.orig_img\n",
    "#     for box in result.boxes:\n",
    "#                 left_x = int(box.xyxy.tolist()[0][0])\n",
    "#                 left_y = int(box.xyxy.tolist()[0][1])\n",
    "#                 right_x = int(box.xyxy.tolist()[0][2])\n",
    "#                 right_y = int(box.xyxy.tolist()[0][3])\n",
    "                \n",
    "#                 face = ori[left_y:right_y, left_x:right_x]\n",
    "                \n",
    "#                 ori[left_y:right_y, left_x:right_x] = cv2.blur(face, (40, 40))\n",
    "    \n",
    "#     saveVideo.write(ori)\n",
    "\n",
    "\n",
    "# saveVideo.release() #1분 46초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 1674/1674.0 [01:44<00:00, 16.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# 프레임이 아닌 비디오를 모델의 입력으로...\n",
    "model = YOLO('../model/yolov8m-face.pt')\n",
    "videoPath = 'testvideoShorts.mp4'\n",
    "\n",
    "results = model(videoPath, stream=True ,verbose=False,show_labels=False ,device='mps')\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(videoPath)\n",
    "fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
    "w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "saveVideo = cv2.VideoWriter('outputShorts.mp4', fourcc, fps, (w, h))\n",
    "frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "for result in tqdm(results,  total=frame_count):\n",
    "    ori = result.orig_img\n",
    "    for box in result.boxes:\n",
    "                left_x = int(box.xyxy.tolist()[0][0])\n",
    "                left_y = int(box.xyxy.tolist()[0][1])\n",
    "                right_x = int(box.xyxy.tolist()[0][2])\n",
    "                right_y = int(box.xyxy.tolist()[0][3])\n",
    "                \n",
    "                face = ori[left_y:right_y, left_x:right_x]\n",
    "                \n",
    "                ori[left_y:right_y, left_x:right_x] = cv2.blur(face, (40, 40))\n",
    "    \n",
    "    saveVideo.write(ori)\n",
    "\n",
    "\n",
    "saveVideo.release() #1분 45초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = YOLO('../model/yolov8m-face.pt')\n",
    "# cap = cv2.VideoCapture('testvideoShorts.mp4')\n",
    "# fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
    "# w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "# saveVideo = cv2.VideoWriter('outputShort.mp4', fourcc, fps, (w, h))\n",
    "\n",
    "# for i in tqdm(range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))):\n",
    "# # while(True):\n",
    "#     retval, frame = cap.read()\n",
    "    \n",
    "#     if not(retval):\t# 프레임정보를 정상적으로 읽지 못하면\n",
    "#         break  # while문을 빠져나가기\n",
    "    \n",
    "#     else:\n",
    "#         results = model(frame, verbose=False)\n",
    "#         boxes = results[0].boxes\n",
    "        \n",
    "#         for box in boxes:\n",
    "#             left_x = int(box.xyxy.tolist()[0][0])\n",
    "#             left_y = int(box.xyxy.tolist()[0][1])\n",
    "#             right_x = int(box.xyxy.tolist()[0][2])\n",
    "#             right_y = int(box.xyxy.tolist()[0][3])\n",
    "            \n",
    "#             face = frame[left_y:right_y, left_x:right_x]\n",
    "            \n",
    "#             frame[left_y:right_y, left_x:right_x] = cv2.blur(face, (40, 40))\n",
    "            \n",
    "#         saveVideo.write(frame)\n",
    "            \n",
    "#         if cv2.waitKey(1) == ord('q'):\n",
    "#             break\n",
    "\n",
    "    \n",
    "# if cap.isOpened():\t# 영상 파일(카메라)이 정상적으로 열렸는지(초기화되었는지) 여부\n",
    "#     cap.release()\t# 영상 파일(카메라) 사용을 종료\n",
    "#     saveVideo.release()\n",
    "    \n",
    "# cv2.destroyAllWindows() \n",
    "# cv2.waitKey(1) #맥에서 창 종료가 안되는 문제 해결\n",
    "# cv2.waitKey(1)\n",
    "# cv2.waitKey(1)\n",
    "# cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
